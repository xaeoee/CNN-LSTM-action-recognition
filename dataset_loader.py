import torch
import os
from torch.utils.data import Dataset, DataLoader
import random

class VideoDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.data = []  # (íŒŒì¼ ê²½ë¡œ, í´ë˜ìŠ¤ ë¼ë²¨) ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        self.class_labels = sorted(os.listdir(root_dir))  # í´ë”ëª… ê¸°ì¤€ ì •ë ¬

        for label_idx, class_name in enumerate(self.class_labels):
            class_folder = os.path.join(root_dir, class_name)
            if not os.path.isdir(class_folder):
                continue  # í´ë”ê°€ ì•„ë‹ˆë©´ ìŠ¤í‚µ
            
            video_files = sorted([f for f in os.listdir(class_folder) if f.endswith('.pt')])
            for video_file in video_files:
                video_path = os.path.join(class_folder, video_file)
                self.data.append((video_path, label_idx))  # (íŒŒì¼ ê²½ë¡œ, ë¼ë²¨) ì €ì¥

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # ë§¤ iteration ë§ˆë‹¤ í˜¸ì¶œë¨
        # 


        video_path, label = self.data[idx]
        video_tensor = torch.load(video_path)  # (30, 3, 224, 224) í˜•íƒœ ìœ ì§€

        # print(f"ğŸ“Œ __getitem__ í˜¸ì¶œë¨: idx={idx}, label={label}")

        
        if self.transform:
            video_tensor = self.transform(video_tensor)

        return video_tensor, label  # (30, 3, 224, 224), ì •ìˆ˜ ë¼ë²¨

def get_dataloaders(root_dir, batch_size=8, shuffle=True, train_split=0.8, val_split=0.1):

    dataset = VideoDataset(root_dir) #ë°ì´í„°ì…‹ ë§Œë“¤ê¸°
    total_size = len(dataset)
    
    # ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ ì„ê¸° (ëœë¤ ìƒ˜í”Œë§)
    indices = list(range(total_size))
    random.shuffle(indices)

    train_size = int(train_split * total_size)
    val_size = int(val_split * total_size)
    test_size = total_size - train_size - val_size

    train_indices = indices[:train_size]
    val_indices = indices[train_size:train_size + val_size]
    test_indices = indices[train_size + val_size:]

    train_set = torch.utils.data.Subset(dataset, train_indices)
    val_set = torch.utils.data.Subset(dataset, val_indices)
    test_set = torch.utils.data.Subset(dataset, test_indices)

    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=shuffle) #ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ë•Œ ë¯¸ë‹ˆë°°ì¹˜ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° í¸í•˜ê²Œ í•´ì£¼ëŠ”ê²Œ dataloaders
    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader, test_loader

if __name__ == "__main__":
    root_dir = "processed_videos"
    train_loader, val_loader, test_loader = get_dataloaders(root_dir)

    # ë°°ì¹˜ ìƒ˜í”Œ í™•ì¸
    sample_batch = next(iter(train_loader))
    sample_data, sample_label = sample_batch
    print(f"Batch Shape: {sample_data.shape}")  # (batch, 30, 3, 224, 224)
    print(f"Labels: {sample_label}")  # ë°°ì¹˜ ë‚´ í´ë˜ìŠ¤ ë¼ë²¨ í™•ì¸
